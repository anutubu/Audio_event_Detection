{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"GMM_test.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"90oQHMynytNQ"},"source":["import numpy as np\n","import librosa \n","import glob\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.stats import multivariate_normal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgCtw2waytNX"},"source":["def load_spectogram(dirname):\n","  i=0;\n","  filename= 'temp'\n","  for name in glob.glob(dirname+'/*.npy'):\n","    spectog = np.load(name)\n","    name = name[12:len(name)-4]\n","    if(i==0):\n","      spec= np.empty((0,spectog.shape[0],spectog.shape[1]))\n","    #  name = name[12:len(name)-4]\n","      filename = name\n","      i=1\n","    elif(i==1):\n","      filename = np.vstack([filename,name])\n","    spectog=spectog.reshape((1,spectog.shape[0],spectog.shape[1]))\n","    spec=np.vstack([spec,spectog])\n","  #print(filename)\n","  return filename,spec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS2ze7jqytNZ"},"source":["def meanfilt (x, k):\n","    \"\"\"Apply a length-k mean filter to a 1D array x.\n","    Boundaries are extended by repeating endpoints.\n","    \"\"\"\n","    \n","    import numpy as np\n","    x = np.reshape(x,(x.shape[1]))\n","    assert k % 2 == 1, \"Median filter length must be odd.\"\n","    assert x.ndim == 1, \"Input must be one-dimensional.\"\n","    \n","    k2 = (k - 1) // 2\n","    y = np.zeros ((len (x), k), dtype=x.dtype)\n","    y[:,k2] = x\n","    for i in range (k2):\n","        j = k2 - i\n","        y[j:,i] = x[:-j]\n","        y[:j,i] = x[0]\n","        y[:-j,-(i+1)] = x[j:]\n","        y[-j:,-(i+1)] = x[-1]\n","    return np.mean (y, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHoocK3ZytNa"},"source":["def calc_threshold_and_rmse(spec):\n","  thres=np.empty((spec.shape[0],1))\n","  rmse = np.empty((0,spec[0].shape[1]))\n","  for i in range(0,spec.shape[0]):\n","      a=librosa.decompose.nn_filter(spec[i],aggregate=np.average)\n","      rmse_val = librosa.feature.rms(S=a,frame_length=1024, hop_length=512)\n","      rmse_val = meanfilt(rmse_val,11)\n","      rmse=np.vstack([rmse,rmse_val])\n","      max=np.max(rmse_val[15:rmse_val.shape[0]])\n","      min=np.min(rmse_val)\n","      thres[i] =  (0.965)*max+(0.035)*(min)\n","      thresarr = np.full((spec[0].shape[1],1),thres[i])\n","      #plt.figure()\n","      #plt.plot(rmse_val, label='RMS Energy')\n","      #plt.plot(thresarr)\n","  return thres,rmse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_OWYlE7ytNb"},"source":["def calc_timestamp(thres,rmse,filename):\n","  time_stamp = np.empty((0,3))\n","  a = np.empty((1,3))\n","  names = np.empty((0,1))\n","  for i in range(0,rmse.shape[0]):\n","      j=0\n","      prev=rmse[j];\n","      j=1\n","      while j<rmse.shape[1]:\n","          if(rmse[i][j]<=thres[i]):\n","              index=i\n","              onset=j\n","              while (j<rmse.shape[1] and rmse[i][j]<=thres[i]):\n","                  j=j+1\n","              offset=j\n","              a[0][0]=index\n","              a[0][1]=onset\n","              a[0][2]=offset\n","              #print(filename[index],onset,offset,index)\n","              if(offset - onset >=25):\n","                time_stamp=np.vstack([time_stamp,a])\n","                names = np.vstack([names,filename[index]])\n","          if(j<rmse.shape[1] and rmse[i][j]>thres[i]):\n","              j=j+1;\n","  return time_stamp,names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTzaMUpRytNc"},"source":["def aggregate_label_GMM(a):\n","  count_speech=0\n","  count_music = 0\n","  for i in range(0,a.shape[0]):\n","    if(a[i][1]>a[i][0]):\n","      count_music=count_music+1\n","    else:\n","      count_speech=count_speech+1\n","  #print(count_music,count_speech)\n","  if(count_speech>count_music):\n","    return 0\n","  else:\n","    return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5ol0Mj6ytNd"},"source":["def label_timestamp_GMM(gmm_music,gmm_speech,spec,time_stamp):\n","  l = np.full((time_stamp.shape[0],1),0)\n","  k=0\n","  for i in time_stamp:\n","    temp_spec = spec[int(i[0])][:,int(i[1]):int(i[2])]\n","    #print(temp_spec.shape)\n","    reduced_spec = PCA(np.float64(temp_spec).T)\n","    a = np.full((reduced_spec.shape[1],2),0.0) \n","    #print(a[:,1].shape)\n","    #print((gmm_music.predict(reduced_spec.T).reshape((reduced_spec.shape[1],))).shape)\n","    a[:,1] = gmm_music.predict(reduced_spec.T).reshape((reduced_spec.shape[1],))\n","    a[:,0] = gmm_speech.predict(reduced_spec.T).reshape((reduced_spec.shape[1],))\n","    #print(a)\n","    if(aggregate_label_GMM(a)==0):\n","      l[k][0]=0\n","    else:\n","      l[k][0]=1\n","    k=k+1\n","  return l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvwl-g_FytNe"},"source":["def PCA(spec):\n","    spec2 = spec - np.average(spec,axis=0)\n","    cov_mat =np.cov(spec2, rowvar = False) #each column represents a variable\n","    eigen_values, eigen_vectors = np.linalg.eig(cov_mat)\n","    sorted_index = np.argsort(eigen_values)[::-1]\n","    sorted_eigenvalue = eigen_values[sorted_index]\n","    sorted_eigenvectors = eigen_vectors[:,sorted_index]\n","    n_com = 16\n","    eigenvector_subset = sorted_eigenvectors[:,0:n_com]\n","    spec_reduced = np.dot(eigenvector_subset.transpose(),spec2.transpose()).transpose()\n","    return spec_reduced.T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4q08ox9eytNe"},"source":["class GMM_music:\n","    def __init__(self,k,max_iter=5):\n","        self.k = k\n","        self.max_iter = int(max_iter)\n","    \n","    def initialize(self, X):\n","        self.shape = X.shape\n","        self.n, self.m = self.shape\n","        \n","        self.pi = np.full(shape=self.k, fill_value=1/self.k)\n","        self.gamma = np.full(shape =self.shape, fill_value=1/self.k) #P(zi = j/x,theta)probability that xi comes from cluster j\n","\n","        random_row = np.random.randint(low=0, high=self.n, size=self.k)\n","        self.mu = [  X[row_index,:] for row_index in random_row ]\n","        self.sigma = [ np.cov(X.T) for _ in range(self.k) ]\n","       # print(X.shape)\n","       # print(self.pi.shape,self.gamma.shape,len(self.mu),len(self.sigma))\n","\n","    def e_step(self, X):\n","        self.gamma = self.predict_proba(X)\n","        self.pi = self.gamma.mean(axis=0)\n","        \n","    def m_step(self, X):\n","        for i in range(self.k):\n","            gamma = self.gamma[:, [i]]\n","            total_gamma = gamma.sum()\n","            self.mu[i] = (X * gamma).sum(axis=0)/total_gamma\n","            self.sigma[i] = np.cov(X.T, \n","                aweights=(gamma/total_gamma).flatten(), \n","                bias=True)\n","        \n","    def fit(self, X):\n","        self.initialize(X)\n","        for iteration in range(self.max_iter):\n","            self.e_step(X)\n","            self.m_step(X)\n","        self.saveweights(self.k,self.mu,self.sigma,self.pi, 'music_k.npy', 'music_mu.npy', 'music_sigma.npy', 'music_pi.npy')\n","    \n","    def saveweights(self,k, mu , sigma, pi,kn,mun,sigman,pin):\n","      assert kn[-4:]=='.npy'\n","      assert mun[-4:]=='.npy' \n","      assert pin[-4:]=='.npy'\n","      assert sigman[-4:]=='.npy' \n","      np.save(kn, k)\n","      np.save(mun, mu)\n","      np.save(sigman, sigma)\n","      np.save(pin, pi)\n","      return\n","\n","    def readweights(self,kn, mun,sigman,pin):\n","      self.k = np.load(kn) \n","      self.mu = np.load(mun)\n","      self.sigma = np.load(sigman)\n","      self.pi = np.load(pin)\n","      return self.k, self.mu, self.sigma, self.pi\n","\n","    \n","        \n","    \n","    def predict_proba(self, X):\n","        likelihood = np.zeros( (X.shape[0], self.k) )\n","        for i in range(self.k):\n","            #print(self.mu[i])\n","            distribution = multivariate_normal(\n","                mean=self.mu[i], \n","                cov=self.sigma[i])\n","            likelihood[:,i] = distribution.pdf(X)\n","        #print(likelihood)\n","        numerator = likelihood * self.pi\n","      #  print('h',numerator.shape,likelihood.shape,numerator[0,0])\n","        denominator = numerator.sum(axis=1)[:, np.newaxis]\n","       # print(denominator)\n","        gamma = numerator / denominator\n","        return gamma\n","        \n","    def predict(self, X):\n","        likelihood = np.zeros( (X.shape[0], self.k) )\n","        for i in range(self.k):\n","            distribution = multivariate_normal(\n","                mean=self.mu[i], \n","                cov=self.sigma[i])\n","            likelihood[:,i] = distribution.pdf(X)\n","        numerator = likelihood * self.pi\n","        sum_numerator=numerator.sum(axis=1)[:, np.newaxis]\n","        return sum_numerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52ArRGwoytNg"},"source":["class GMM_speech:\n","    def __init__(self,k,max_iter=5):\n","        self.k = k\n","        self.max_iter = int(max_iter)\n","    \n","    def initialize(self, X):\n","        self.shape = X.shape\n","        self.n, self.m = self.shape\n","        \n","        self.pi = np.full(shape=self.k, fill_value=1/self.k)\n","        self.gamma = np.full(shape =self.shape, fill_value=1/self.k) #P(zi = j/x,theta)probability that xi comes from cluster j\n","\n","        random_row = np.random.randint(low=0, high=self.n, size=self.k)\n","        self.mu = [  X[row_index,:] for row_index in random_row ]\n","        self.sigma = [ np.cov(X.T) for _ in range(self.k) ]\n","      #  print(X.shape)\n","      #  print(self.pi.shape,self.gamma.shape,len(self.mu),len(self.sigma))\n","\n","    def e_step(self, X):\n","        self.gamma = self.predict_proba(X)\n","        self.pi = self.gamma.mean(axis=0)\n","        \n","    def m_step(self, X):\n","        for i in range(self.k):\n","            gamma = self.gamma[:, [i]]\n","            total_gamma = gamma.sum()\n","            self.mu[i] = (X * gamma).sum(axis=0)/total_gamma\n","            self.sigma[i] = np.cov(X.T, \n","                aweights=(gamma/total_gamma).flatten(), \n","                bias=True)\n","        \n","    def fit(self, X):\n","        self.initialize(X)\n","        for iteration in range(self.max_iter):\n","            self.e_step(X)\n","            self.m_step(X)\n","        self.saveweights(self.k,self.mu,self.sigma,self.pi, 'speech_k.npy', 'speech_mu.npy', 'speech_sigma.npy', 'speech_pi.npy')\n","    \n","    def saveweights(self,k, mu , sigma, pi,kn,mun,sigman,pin):\n","      assert kn[-4:]=='.npy'\n","      assert mun[-4:]=='.npy' \n","      assert pin[-4:]=='.npy'\n","      assert sigman[-4:]=='.npy' \n","      np.save(kn, k)\n","      np.save(mun, mu)\n","      np.save(sigman, sigma)\n","      np.save(pin, pi)\n","      return\n","\n","    def readweights(self,kn, mun,sigman,pin):\n","      self.k = np.load(kn) \n","      self.mu = np.load(mun)\n","      self.sigma = np.load(sigman)\n","      self.pi = np.load(pin)\n","      return self.k, self.mu, self.sigma, self.pi\n","        \n","    \n","    def predict_proba(self, X):\n","        likelihood = np.zeros( (X.shape[0], self.k) )\n","        for i in range(self.k):\n","            #print(self.mu[i])\n","            distribution = multivariate_normal(\n","                mean=self.mu[i], \n","                cov=self.sigma[i])\n","            likelihood[:,i] = distribution.pdf(X)\n","       # print(likelihood)\n","        numerator = likelihood * self.pi\n","        print('h',numerator.shape,likelihood.shape,numerator[0,0])\n","        denominator = numerator.sum(axis=1)[:, np.newaxis]\n","       # print(denominator)\n","        gamma = numerator / denominator\n","        return gamma\n","        \n","    def predict(self, X):\n","        likelihood = np.zeros( (X.shape[0], self.k) )\n","        for i in range(self.k):\n","            distribution = multivariate_normal(\n","                mean=self.mu[i], \n","                cov=self.sigma[i])\n","            likelihood[:,i] = distribution.pdf(X)\n","        numerator = likelihood * self.pi\n","        sum_numerator=numerator.sum(axis=1)[:, np.newaxis]\n","        return sum_numerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pj1L1Wl_ytNh","outputId":"da9a107e-39d5-4189-91d8-59a063cbba87"},"source":["if __name__==\"__main__\":\n","    filename,spec = load_spectogram('spectrogram')########\n","    thres,rmse = calc_threshold_and_rmse(spec)\n","    time_stamp,names = calc_timestamp(thres,rmse,filename)\n","    np.random.seed(42)\n","    gmm_speech = GMM_speech(k=1, max_iter=20)\n","    gmm_speech.readweights('GMM_weights/speech_k.npy', 'GMM_weights/speech_mu.npy', 'GMM_weights/speech_sigma.npy', 'GMM_weights/speech_pi.npy')\n","    np.random.seed(42)\n","    gmm_music = GMM_music(k=1, max_iter=20)\n","    gmm_music.readweights('GMM_weights/music_k.npy', 'GMM_weights/music_mu.npy', 'GMM_weights/music_sigma.npy', 'GMM_weights/music_pi.npy')\n","    l=label_timestamp_GMM(gmm_music,gmm_speech,spec,time_stamp)\n","    for i  in range(0,time_stamp.shape[0]):\n","        time_stamp[i,1]= ((time_stamp[i,1]-1)*512 + 1024)/16000\n","        time_stamp[i,2]= ((time_stamp[i,2]-1)*512 + 1024)/16000\n","    final_time_stamp_GMM=np.hstack([time_stamp,l])\n","    k=0\n","    for i in range(0,l.shape[0]):\n","        if(l[i][0]==0):\n","            if(k==0):\n","                b='Speech'\n","                k=1\n","            else:\n","                b=np.vstack([b,'Speech'])\n","        else:\n","            if(k==0):\n","                b='Music'\n","                k=1\n","            else:\n","                b=np.vstack([b,'Music'])\n","    DF1 = pd.DataFrame(names,columns=['filename'])\n","    DF2 = pd.DataFrame(b,columns=['event'])\n","    DF3 = pd.DataFrame(final_time_stamp_GMM[:,1],columns=['onset'])\n","    DF4 = pd.DataFrame(final_time_stamp_GMM[:,2],columns=['offset'])\n","    frames = [DF1,DF2,DF3,DF4]\n","    result = pd.concat(frames,axis=1)\n","    #final = np.hstack([names.reshape((names.shape[0],)).T,final_time_stamp_NN[:,1].T,final_time_stamp_NN[:,2].T,b.reshape((b.shape[0],)).T])\n","    print(result)\n","    result.to_csv('GMM_event_detection.csv',index=False)\n","    #df = pd.read_csv('labels.csv')\n","    #final_time_stamp_kmeans[:,0] = names  \n","    #d= np.hstack([final_time_stamp_GMM,names])\n","    #print(final_time_stamp_kmeans,names, df, d)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anubhav/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n","  return array(a, dtype, copy=False, order=order)\n"]},{"name":"stdout","output_type":"stream","text":["                filename   event  onset  offset\n","0                   S009  Speech  0.320   2.528\n","1                   S009  Speech  3.520   5.600\n","2                   S009  Speech  6.656   9.280\n","3           music_noisy8   Music  0.256   2.592\n","4           music_noisy8   Music  4.128   7.136\n","..                   ...     ...    ...     ...\n","96          music_noisy3   Music  3.296   8.736\n","97   music+speech_noisy5   Music  0.224   2.016\n","98   music+speech_noisy5   Music  2.400   3.840\n","99   music+speech_noisy5   Music  4.576   6.336\n","100  music+speech_noisy5   Music  7.136   8.512\n","\n","[101 rows x 4 columns]\n"]}]},{"cell_type":"code","metadata":{"id":"NqTaeThyytNk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w0lKYRkbytNk"},"source":[""],"execution_count":null,"outputs":[]}]}