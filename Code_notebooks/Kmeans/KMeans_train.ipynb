{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAudio(filename):\n",
    "    x, sr = librosa.load(filename, sr=16000)\n",
    "    return x, sr\n",
    "\n",
    "#calculate spectrogram\n",
    "def calc_spec(x):\n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    win_length = 1024\n",
    "    X = np.abs(librosa.stft(x, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = np.complex256))\n",
    "    X = librosa.power_to_db(X**2,ref=np.max)\n",
    "    return X\n",
    "\n",
    "def saveSpectrogram(X, outfilename):\n",
    "    assert outfilename[-4:]=='.npy'  #'outfilename extension should be .npy'\n",
    "    np.save(outfilename, X)\n",
    "    return\n",
    "\n",
    "def readSpectrogram(infilename):\n",
    "    X = np.load(infilename)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combine_speech_music_spec():\n",
    "  p=0\n",
    "  for i in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18']:\n",
    "    name = 'music_samples'+'/' + i + '.wav'\n",
    "    print(name)\n",
    "    audio, sr = readAudio(name,16000)\n",
    "    if p==0:\n",
    "      music_data = audio\n",
    "      p=1\n",
    "    elif p==1:\n",
    "      music_data = np.hstack((music_data,audio))\n",
    "  p=0\n",
    "  for i in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']:\n",
    "    name = 'speech_samples'+'/' + i + '.wav'\n",
    "    print(name)\n",
    "    audio, sr = readAudio(name,16000)\n",
    "    if p==0:\n",
    "      speech_data = audio\n",
    "      p=1\n",
    "    elif p==1:\n",
    "      speech_data = np.hstack((speech_data,audio))\n",
    "  speech_spec=calc_spec(speech_data)\n",
    "  label_speech = np.zeros((speech_spec.shape[1],))\n",
    "  music_spec=calc_spec(music_data)\n",
    "  label_music = np.ones((music_spec.shape[1],))\n",
    "  label = np.hstack([label_speech,label_music])\n",
    "  combine = np.hstack([speech_spec,music_spec])\n",
    "  return speech_spec, music_spec, label, combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "class Kmeans:\n",
    "    def __init__(self,X,lab,K):\n",
    "        self.X=X\n",
    "        self.Output={}\n",
    "        self.Centroids=np.array([]).reshape(self.X.shape[1],0)\n",
    "        self.K=K\n",
    "        self.m=self.X.shape[0]\n",
    "        self.lab=lab\n",
    "        self.labb=[0,1]\n",
    "    def kmeanspp(self,X,K):\n",
    "        for i in range(K):\n",
    "            rand=rd.randint(0,self.m-1)\n",
    "            self.Centroids=np.c_[self.Centroids,X[rand]]\n",
    "        return self.Centroids\n",
    "    def fit(self,n_iter):\n",
    "        self.Centroids=self.kmeanspp(self.X,self.K)\n",
    "        Output={}\n",
    "        for j in range(n_iter):\n",
    "            EuclidianDistance=np.array([]).reshape(self.m,0)\n",
    "            for k in range(self.K):\n",
    "                tempDist=np.sum((self.X-self.Centroids[:,k])**2,axis=1)\n",
    "                EuclidianDistance=np.c_[EuclidianDistance,tempDist]\n",
    "            a = np.average(EuclidianDistance,axis=0)\n",
    "            b = np.average(a)\n",
    "            C=np.argmin(EuclidianDistance,axis=1)+1\n",
    "            Y={}\n",
    "            la={}\n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=np.array([]).reshape(513,0)\n",
    "                la[k+1]=np.array([]).reshape(1,0)\n",
    "                \n",
    "            for i in range(self.m):\n",
    "                Y[C[i]]=np.c_[Y[C[i]],self.X[i]]\n",
    "                la[C[i]]=np.append(la[C[i]],self.lab[i])\n",
    "     \n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=Y[k+1].T\n",
    "                la[k+1]=la[k+1].T\n",
    "                print(Y[k+1].shape)\n",
    "                \n",
    "            for k in range(self.K):\n",
    "                self.Centroids[:,k] = np.mean(Y[k+1],axis=0)\n",
    "            print('cluster1:',np.average(la[1]),'cluster2:',np.average(la[2]),'speech:0, music:1')\n",
    "            plt.figure()\n",
    "            color=['red','blue','green','cyan','magenta']\n",
    "            labels=['cluster1','cluster2','cluster3','cluster4','cluster5']\n",
    "            for k in range(self.K):\n",
    "                plt.scatter(np.average(Y[k+1][:,1:250],axis=1),np.average(Y[k+1][:,250:513],axis=1),c=color[k],label=labels[k])\n",
    "            plt.scatter(np.average(self.Centroids[1:250,:],axis=0),np.average(self.Centroids[250:513,:],axis=0),s=300,c='yellow',label='Centroids')\n",
    "            plt.title('Clusters ')\n",
    "            plt.xlabel('Average spectogram feature values (1:250)')\n",
    "            plt.ylabel('Average spectogram feature values (250:513)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            if(np.average(la[1])>np.average(la[2])):\n",
    "              self.labb[0]=1\n",
    "              self.labb[1]=0\n",
    "            else:\n",
    "              self.labb[0]=0\n",
    "              self.labb[1]=1\n",
    "            self.Output=Y\n",
    "            print(self.labb)\n",
    "        self.saveweights(self.Centroids, self.labb, 'centroid.npy', 'labb.npy')      \n",
    "    \n",
    "    def saveweights(self,centroid, label ,centroid_fn, label_fn):\n",
    "      assert centroid_fn[-4:]=='.npy'\n",
    "      assert label_fn[-4:]=='.npy'  \n",
    "      np.save(centroid_fn, centroid)\n",
    "      np.save(label_fn, label)\n",
    "      return\n",
    "\n",
    "    def readweights(self,centroid_fn, label_fn):\n",
    "      self.Centroids = np.load(centroid_fn) \n",
    "      a = np.load(label_fn)\n",
    "      self.labb[0] = a[0]\n",
    "      self.labb[1] = a[1]\n",
    "      print(self.labb)\n",
    "      return self.Centroids, self.labb\n",
    "    \n",
    "    def predict(self,X):\n",
    "        EuclidianDistance=np.array([]).reshape(X.shape[0],0)\n",
    "        for k in range(self.K):\n",
    "            tempDist=np.sum((X-self.Centroids[:,k])**2,axis=1)\n",
    "            EuclidianDistance=np.c_[EuclidianDistance,tempDist]\n",
    "        a = np.average(EuclidianDistance,axis=0)\n",
    "        b = np.average(a)\n",
    "        ll = np.zeros((X.shape[0],))\n",
    "        for i in range(0,EuclidianDistance.shape[0]):\n",
    "          if(EuclidianDistance[i][0]<EuclidianDistance[i][1]):\n",
    "            ll[i]=self.labb[0]\n",
    "          else:\n",
    "            ll[i]=self.labb[1]\n",
    "        C=np.argmin(EuclidianDistance,axis=1)+1\n",
    "        Y={}\n",
    "        for k in range(self.K):\n",
    "            Y[k+1]=np.array([]).reshape(513,0)\n",
    "                \n",
    "        for i in range(X.shape[0]):\n",
    "            Y[C[i]]=np.c_[Y[C[i]],X[i]]\n",
    "     \n",
    "        for k in range(self.K):\n",
    "            Y[k+1]=Y[k+1].T\n",
    "\n",
    "        return Y,self.Centroids.T,EuclidianDistance,ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Kmeans(combine,label,K,n_iter,speech_spec,music_spec):\n",
    "  kmeans=Kmeans(combine.T,label,K)\n",
    "  kmeans.fit(n_iter)\n",
    "  Output,Centroids,distance,label_speech = kmeans.predict(speech_spec.T)\n",
    "  Output,Centroids,distance,label_music = kmeans.predict(music_spec.T)\n",
    "  weight_speech = 1+abs((np.average(label_speech)-0)*2)\n",
    "  weight_music = 1+abs((np.average(label_music)-1)*3)\n",
    "  np.save('wt_speech.npy', weight_speech)\n",
    "  np.save('wt_music.npy', weight_music)\n",
    "  return weight_speech, weight_music, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_label_kmeans(x,weight_speech,weight_music):\n",
    "  count_s = 0\n",
    "  count_m = 0\n",
    "  for i in x:\n",
    "    if(i==0):\n",
    "      count_s=count_s+1\n",
    "    if(i==1):\n",
    "      count_m=count_m+1\n",
    "  if(count_s*weight_speech > count_m*weight_music):\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_timestamp_kmeans(spec,time_stamp,wt_speech,wt_music,kmeans):\n",
    "  l = np.full((time_stamp.shape[0],1),0) \n",
    "  k=0\n",
    "  for i in time_stamp:\n",
    "    temp_spec = spec[int(i[0])][:,int(i[1]):int(i[2])]\n",
    "    Output,Centroids,distance,labels = kmeans.predict(temp_spec.T)\n",
    "    if(aggregate_label_kmeans(labels,wt_speech,wt_music)==0):\n",
    "      l[k][0]=0\n",
    "    else:\n",
    "      l[k][0]=1\n",
    "    k=k+1\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music_samples/1.wav\n",
      "music_samples/2.wav\n",
      "music_samples/3.wav\n",
      "music_samples/4.wav\n",
      "music_samples/5.wav\n",
      "music_samples/6.wav\n",
      "music_samples/7.wav\n",
      "music_samples/8.wav\n",
      "music_samples/9.wav\n",
      "music_samples/10.wav\n",
      "music_samples/11.wav\n",
      "music_samples/12.wav\n",
      "music_samples/14.wav\n",
      "music_samples/15.wav\n",
      "music_samples/16.wav\n",
      "music_samples/17.wav\n",
      "music_samples/18.wav\n",
      "speech_samples/1.wav\n",
      "speech_samples/2.wav\n",
      "speech_samples/3.wav\n",
      "speech_samples/4.wav\n",
      "speech_samples/5.wav\n",
      "speech_samples/6.wav\n",
      "speech_samples/7.wav\n",
      "speech_samples/8.wav\n",
      "speech_samples/9.wav\n",
      "speech_samples/10.wav\n",
      "speech_samples/11.wav\n",
      "speech_samples/12.wav\n",
      "speech_samples/14.wav\n",
      "speech_samples/15.wav\n",
      "speech_samples/16.wav\n",
      "speech_samples/17.wav\n",
      "speech_samples/18.wav\n",
      "speech_samples/19.wav\n",
      "speech_samples/20.wav\n",
      "speech_samples/21.wav\n",
      "speech_samples/22.wav\n",
      "speech_samples/23.wav\n",
      "speech_samples/24.wav\n",
      "speech_samples/25.wav\n",
      "speech_samples/26.wav\n",
      "speech_samples/27.wav\n",
      "speech_samples/28.wav\n",
      "speech_samples/29.wav\n",
      "speech_samples/30.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ebe26baf05da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m##############Kmeans################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mwt_speech\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt_music\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspeech_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmusic_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m#kmeans=Kmeans(combine.T,label,2)#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#kmeans.readweights('centroid.npy','labb.npy')#####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1231f84e52bc>\u001b[0m in \u001b[0;36mtrain_Kmeans\u001b[0;34m(combine, label, K, n_iter, speech_spec, music_spec)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_Kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspeech_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmusic_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mkmeans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCentroids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_speech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCentroids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-81a157168513>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_iter)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "  #audio_data,spec,sr,music_data, speech_data, filename, onset, offset, label  = readDir('wav')\n",
    "  #filename, spec = load_spectogram('/content/EE603-Machine-Learning-for-Signal-Processing/project/wav_2/EE603-Machine-Learning-for-Signal-Processing/project/wav_2/spectrogram')########\n",
    "  #thres,rmse = calc_threshold_and_rmse(spec)\n",
    "  #time_stamp = calc_timestamp(thres,rmse)\n",
    "  #speech_spec, music_spec, label, combine = combine_speech_music_spec(speech_data,music_data)\n",
    "  speech_spec, music_spec, label, combine = read_and_combine_speech_music_spec() ###############################\n",
    "\n",
    "  ##############Kmeans################################\n",
    "  wt_speech,wt_music,kmeans = train_Kmeans(combine,label,2,30,speech_spec,music_spec)\n",
    "  #kmeans=Kmeans(combine.T,label,2)#################\n",
    "  #kmeans.readweights('centroid.npy','labb.npy')#####################\n",
    "  #wt_speech=np.load('wt_speech.npy');####################\n",
    "  #wt_music=np.load('wt_music.npy');##################\n",
    "  #l=label_timestamp_kmeans(spec,time_stamp,wt_speech,wt_music,kmeans)\n",
    "  #for i  in range(0,time_stamp.shape[0]):\n",
    "  #  time_stamp[i,1]= ((time_stamp[i,1]-1)*512 + 1024)/16000\n",
    "  #  time_stamp[i,2]= ((time_stamp[i,2]-1)*512 + 1024)/16000\n",
    "  #final_time_stamp_kmeans=np.hstack([time_stamp,l])\n",
    "  #df = pd.read_csv('labels.csv')\n",
    "  #print(final_time_stamp_kmeans,'orig', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
