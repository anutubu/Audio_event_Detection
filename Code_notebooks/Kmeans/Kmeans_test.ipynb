{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectogram(dirname):\n",
    "  i=0;\n",
    "  filename= 'temp'\n",
    "  for name in glob.glob(dirname+'/*.npy'):\n",
    "    spectog = np.load(name)\n",
    "    name = name[12:len(name)-4]\n",
    "    if(i==0):\n",
    "      spec= np.empty((0,spectog.shape[0],spectog.shape[1]))\n",
    "    #  name = name[12:len(name)-4]\n",
    "      filename = name\n",
    "      i=1\n",
    "    elif(i==1):\n",
    "      filename = np.vstack([filename,name])\n",
    "    spectog=spectog.reshape((1,spectog.shape[0],spectog.shape[1]))\n",
    "    spec=np.vstack([spec,spectog])\n",
    "  #print(filename)\n",
    "  return filename,spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanfilt (x, k):\n",
    "    \"\"\"Apply a length-k mean filter to a 1D array x.\n",
    "    Boundaries are extended by repeating endpoints.\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    x = np.reshape(x,(x.shape[1]))\n",
    "    assert k % 2 == 1, \"Median filter length must be odd.\"\n",
    "    assert x.ndim == 1, \"Input must be one-dimensional.\"\n",
    "    \n",
    "    k2 = (k - 1) // 2\n",
    "    y = np.zeros ((len (x), k), dtype=x.dtype)\n",
    "    y[:,k2] = x\n",
    "    for i in range (k2):\n",
    "        j = k2 - i\n",
    "        y[j:,i] = x[:-j]\n",
    "        y[:j,i] = x[0]\n",
    "        y[:-j,-(i+1)] = x[j:]\n",
    "        y[-j:,-(i+1)] = x[-1]\n",
    "    return np.mean (y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_threshold_and_rmse(spec):\n",
    "  thres=np.empty((spec.shape[0],1))\n",
    "  rmse = np.empty((0,spec[0].shape[1]))\n",
    "  for i in range(0,spec.shape[0]):\n",
    "      a=librosa.decompose.nn_filter(spec[i],aggregate=np.average)\n",
    "      rmse_val = librosa.feature.rms(S=a,frame_length=1024, hop_length=512)\n",
    "      rmse_val = meanfilt(rmse_val,11)\n",
    "      rmse=np.vstack([rmse,rmse_val])\n",
    "      max=np.max(rmse_val[15:rmse_val.shape[0]])\n",
    "      min=np.min(rmse_val)\n",
    "      thres[i] =  (0.965)*max+(0.035)*(min)\n",
    "      thresarr = np.full((spec[0].shape[1],1),thres[i])\n",
    "      #plt.figure()\n",
    "      #plt.plot(rmse_val, label='RMS Energy')\n",
    "      #plt.plot(thresarr)\n",
    "  return thres,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_timestamp(thres,rmse,filename):\n",
    "  time_stamp = np.empty((0,3))\n",
    "  a = np.empty((1,3))\n",
    "  names = np.empty((0,1))\n",
    "  for i in range(0,rmse.shape[0]):\n",
    "      j=0\n",
    "      prev=rmse[j];\n",
    "      j=1\n",
    "      while j<rmse.shape[1]:\n",
    "          if(rmse[i][j]<=thres[i]):\n",
    "              index=i\n",
    "              onset=j\n",
    "              while (j<rmse.shape[1] and rmse[i][j]<=thres[i]):\n",
    "                  j=j+1\n",
    "              offset=j\n",
    "              a[0][0]=index\n",
    "              a[0][1]=onset\n",
    "              a[0][2]=offset\n",
    "              #print(filename[index],onset,offset,index)\n",
    "              if(offset - onset >=25):\n",
    "                time_stamp=np.vstack([time_stamp,a])\n",
    "                names = np.vstack([names,filename[index]])\n",
    "          if(j<rmse.shape[1] and rmse[i][j]>thres[i]):\n",
    "              j=j+1;\n",
    "  return time_stamp,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "class Kmeans:\n",
    "    def __init__(self,X,lab,K):\n",
    "        self.X=X\n",
    "        self.Output={}\n",
    "        self.Centroids=np.array([]).reshape(self.X.shape[1],0)\n",
    "        self.K=K\n",
    "        self.m=self.X.shape[0]\n",
    "        self.lab=lab\n",
    "        self.labb=[0,1]\n",
    "    def kmeanspp(self,X,K):\n",
    "        for i in range(K):\n",
    "            rand=rd.randint(0,self.m-1)\n",
    "            self.Centroids=np.c_[self.Centroids,X[rand]]\n",
    "        return self.Centroids\n",
    "    def fit(self,n_iter):\n",
    "        self.Centroids=self.kmeanspp(self.X,self.K)\n",
    "        Output={}\n",
    "        for j in range(n_iter):\n",
    "            EuclidianDistance=np.array([]).reshape(self.m,0)\n",
    "            for k in range(self.K):\n",
    "                tempDist=np.sum((self.X-self.Centroids[:,k])**2,axis=1)\n",
    "                EuclidianDistance=np.c_[EuclidianDistance,tempDist]\n",
    "            a = np.average(EuclidianDistance,axis=0)\n",
    "            b = np.average(a)\n",
    "            C=np.argmin(EuclidianDistance,axis=1)+1\n",
    "            Y={}\n",
    "            la={}\n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=np.array([]).reshape(513,0)\n",
    "                la[k+1]=np.array([]).reshape(1,0)\n",
    "                \n",
    "            for i in range(self.m):\n",
    "                Y[C[i]]=np.c_[Y[C[i]],self.X[i]]\n",
    "                la[C[i]]=np.append(la[C[i]],self.lab[i])\n",
    "     \n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=Y[k+1].T\n",
    "                la[k+1]=la[k+1].T\n",
    "                print(Y[k+1].shape)\n",
    "                \n",
    "            for k in range(self.K):\n",
    "                self.Centroids[:,k] = np.mean(Y[k+1],axis=0)\n",
    "            print('cluster1:',np.average(la[1]),'cluster2:',np.average(la[2]),'speech:0, music:1')\n",
    "            plt.figure()\n",
    "            color=['red','blue','green','cyan','magenta']\n",
    "            labels=['cluster1','cluster2','cluster3','cluster4','cluster5']\n",
    "            for k in range(self.K):\n",
    "                plt.scatter(np.average(Y[k+1][:,1:250],axis=1),np.average(Y[k+1][:,250:513],axis=1),c=color[k],label=labels[k])\n",
    "            plt.scatter(np.average(self.Centroids[1:250,:],axis=0),np.average(self.Centroids[250:513,:],axis=0),s=300,c='yellow',label='Centroids')\n",
    "            plt.title('Clusters ')\n",
    "            plt.xlabel('Average spectogram feature values (1:250)')\n",
    "            plt.ylabel('Average spectogram feature values (250:513)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            if(np.average(la[1])>np.average(la[2])):\n",
    "              self.labb[0]=1\n",
    "              self.labb[1]=0\n",
    "            else:\n",
    "              self.labb[0]=0\n",
    "              self.labb[1]=1\n",
    "            self.Output=Y\n",
    "            print(self.labb)\n",
    "        self.saveweights(self.Centroids, self.labb, 'centroid.npy', 'labb.npy')      \n",
    "    \n",
    "    def saveweights(self,centroid, label ,centroid_fn, label_fn):\n",
    "      assert centroid_fn[-4:]=='.npy'\n",
    "      assert label_fn[-4:]=='.npy'  \n",
    "      np.save(centroid_fn, centroid)\n",
    "      np.save(label_fn, label)\n",
    "      return\n",
    "\n",
    "    def readweights(self,centroid_fn, label_fn):\n",
    "      self.Centroids = np.load(centroid_fn) \n",
    "      a = np.load(label_fn)\n",
    "      self.labb[0] = a[0]\n",
    "      self.labb[1] = a[1]\n",
    "      print(self.labb)\n",
    "      return self.Centroids, self.labb\n",
    "    \n",
    "    def predict(self,X):\n",
    "        EuclidianDistance=np.array([]).reshape(X.shape[0],0)\n",
    "        for k in range(self.K):\n",
    "            tempDist=np.sum((X-self.Centroids[:,k])**2,axis=1)\n",
    "            EuclidianDistance=np.c_[EuclidianDistance,tempDist]\n",
    "        a = np.average(EuclidianDistance,axis=0)\n",
    "        b = np.average(a)\n",
    "        ll = np.zeros((X.shape[0],))\n",
    "        for i in range(0,EuclidianDistance.shape[0]):\n",
    "          if(EuclidianDistance[i][0]<EuclidianDistance[i][1]):\n",
    "            ll[i]=self.labb[0]\n",
    "          else:\n",
    "            ll[i]=self.labb[1]\n",
    "        C=np.argmin(EuclidianDistance,axis=1)+1\n",
    "        Y={}\n",
    "        for k in range(self.K):\n",
    "            Y[k+1]=np.array([]).reshape(513,0)\n",
    "                \n",
    "        for i in range(X.shape[0]):\n",
    "            Y[C[i]]=np.c_[Y[C[i]],X[i]]\n",
    "     \n",
    "        for k in range(self.K):\n",
    "            Y[k+1]=Y[k+1].T\n",
    "\n",
    "        return Y,self.Centroids.T,EuclidianDistance,ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_label_kmeans(x,weight_speech,weight_music):\n",
    "  count_s = 0\n",
    "  count_m = 0\n",
    "  for i in x:\n",
    "    if(i==0):\n",
    "      count_s=count_s+1\n",
    "    if(i==1):\n",
    "      count_m=count_m+1\n",
    "  if(count_s*weight_speech > count_m*weight_music):\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_timestamp_kmeans(spec,time_stamp,wt_speech,wt_music,kmeans):\n",
    "  l = np.full((time_stamp.shape[0],1),0) \n",
    "  k=0\n",
    "  for i in time_stamp:\n",
    "    temp_spec = spec[int(i[0])][:,int(i[1]):int(i[2])]\n",
    "    Output,Centroids,distance,labels = kmeans.predict(temp_spec.T)\n",
    "    if(aggregate_label_kmeans(labels,wt_speech,wt_music)==0):\n",
    "      l[k][0]=0\n",
    "    else:\n",
    "      l[k][0]=1\n",
    "    k=k+1\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "                filename   event  onset  offset\n",
      "0                   S009  Speech  0.320   2.528\n",
      "1                   S009  Speech  3.520   5.600\n",
      "2                   S009  Speech  6.656   9.280\n",
      "3           music_noisy8   Music  0.256   2.592\n",
      "4           music_noisy8  Speech  4.128   7.136\n",
      "..                   ...     ...    ...     ...\n",
      "96          music_noisy3   Music  3.296   8.736\n",
      "97   music+speech_noisy5   Music  0.224   2.016\n",
      "98   music+speech_noisy5   Music  2.400   3.840\n",
      "99   music+speech_noisy5   Music  4.576   6.336\n",
      "100  music+speech_noisy5   Music  7.136   8.512\n",
      "\n",
      "[101 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "      #audio_data,spec,sr,music_data, speech_data, filename, onset, offset, label  = readDir('wav')\n",
    "    filename,spec = load_spectogram('spectrogram')########\n",
    "    thres,rmse = calc_threshold_and_rmse(spec)\n",
    "    time_stamp,names = calc_timestamp(thres,rmse,filename)\n",
    "  #speech_spec, music_spec, label, combine = combine_speech_music_spec(speech_data,music_data)\n",
    "  #speech_spec, music_spec, label, combine = read_and_combine_speech_music_spec() ###############################\n",
    "\n",
    "  ##############Kmeans################################\n",
    "  #wt_speech,wt_music,kmeans = train_Kmeans(combine,label,2,30,speech_spec,music_spec)\n",
    "    kmeans=Kmeans(spec[0].T,3,2)#################\n",
    "    kmeans.readweights('Kmeans_weights/centroid.npy','Kmeans_weights/labb.npy')#####################\n",
    "    wt_speech=np.load('Kmeans_weights/wt_speech.npy');####################\n",
    "    wt_music=np.load('Kmeans_weights/wt_music.npy');##################\n",
    "    l=label_timestamp_kmeans(spec,time_stamp,wt_speech,wt_music,kmeans)\n",
    "    for i  in range(0,time_stamp.shape[0]):\n",
    "        time_stamp[i,1]= ((time_stamp[i,1]-1)*512 + 1024)/16000\n",
    "        time_stamp[i,2]= ((time_stamp[i,2]-1)*512 + 1024)/16000\n",
    "    final_time_stamp_kmeans=np.hstack([time_stamp,l])\n",
    "    k=0\n",
    "    for i in range(0,l.shape[0]):\n",
    "        if(l[i][0]==1):\n",
    "            if(k==0):\n",
    "                b='Speech'\n",
    "                k=1\n",
    "            else:\n",
    "                b=np.vstack([b,'Speech'])\n",
    "        else:\n",
    "            if(k==0):\n",
    "                b='Music'\n",
    "                k=1\n",
    "            else:\n",
    "                b=np.vstack([b,'Music'])\n",
    "    DF1 = pd.DataFrame(names,columns=['filename'])\n",
    "    DF2 = pd.DataFrame(b,columns=['event'])\n",
    "    DF3 = pd.DataFrame(final_time_stamp_kmeans[:,1],columns=['onset'])\n",
    "    DF4 = pd.DataFrame(final_time_stamp_kmeans[:,2],columns=['offset'])\n",
    "    frames = [DF1,DF2,DF3,DF4]\n",
    "    result = pd.concat(frames,axis=1)\n",
    "    #final = np.hstack([names.reshape((names.shape[0],)).T,final_time_stamp_NN[:,1].T,final_time_stamp_NN[:,2].T,b.reshape((b.shape[0],)).T])\n",
    "    print(result)\n",
    "    result.to_csv('Kmeans_event_detection.csv',index=False)\n",
    "\n",
    "  ################NN####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
